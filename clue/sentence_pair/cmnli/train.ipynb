{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMNLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语言推理任务 Chinese Multi-Genre NLI\n",
    "\n",
    "CMNLI数据由两部分组成：XNLI和MNLI。数据来自于fiction，telephone，travel，government，slate等，对原始MNLI数据和XNLI数据进行了中英文转化，保留原始训练集，合并XNLI中的dev和MNLI中的matched作为CMNLI的dev，合并XNLI中的test和MNLI中的mismatched作为CMNLI的test，并打乱顺序。该数据集可用于判断给定的两个句子之间属于蕴涵、中立、矛盾关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclue.tf1.tasks.sentence_pair.siamese.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据所在路径\n",
    "data_dir = '/workspace/projects/PyCLUE_Corpus/sentence_pair/cmnli'\n",
    "# 训练结果保存路径\n",
    "output_dir = '/workspace/projects/PyCLUE_examples/cmnli'\n",
    "\n",
    "# 是否重新创建tfrecord（会耗费一定时间，首次执行时需设置为True；当设为False时，可保证数据一致性）\n",
    "recreate_tfrecord = True\n",
    "# 随机种子\n",
    "random_seed = 0\n",
    "\n",
    "# 使用内置的预训练语言模型时，需指定model_name，无需指定model_type, vocab_file, config_file和init_checkpoint_file\n",
    "# 使用自定义预训练语言模型时，需指定model_type, vocab_file, config_file和init_checkpoint_file，无需指定model_name\n",
    "model_name = 'albert_tiny_zh_brightmart'\n",
    "model_type = None\n",
    "vocab_file = None\n",
    "config_file = None\n",
    "init_checkpoint_file = None\n",
    "\n",
    "# 训练时能接受的最长句长，注：该句长不能超过预训练时所指定的最大句长\n",
    "max_seq_len = 128\n",
    "# 训练步数(num_train_steps) = 训练数据量(num_train_examples) * 训练轮次(num_train_epochs) / 每批次训练数据大小(batch_size)\n",
    "# 预热步数(num_warmup_steps) = 训练步数(num_train_steps) * 预热比例(warmup_proportion)\n",
    "# 训练轮次\n",
    "num_train_epochs = 2\n",
    "# 预热比例\n",
    "warmup_proportion = 0.1\n",
    "# 每批次训练数据大小\n",
    "batch_size = 64\n",
    "\n",
    "# 初始学习率\n",
    "learning_rate = 3e-5\n",
    "# 训练器名，可选adamw和lamb\n",
    "optimizer_name = 'adamw'\n",
    "\n",
    "# 验证指标，可选accuracy, premise, recall, f1\n",
    "metric_name = 'accuracy'\n",
    "\n",
    "# 每若干训练步数保存一次checkpoint模型（最多保存最新的10个模型）\n",
    "save_checkpoints_steps = 200\n",
    "# 每若干训练步数打印一次训练指标\n",
    "log_steps = 50\n",
    "# 训练与验证执行策略，可选0（异步：先训练后验证，较快，CLUE默认采用此方式）或1（同步：同时执行训练与验证，较慢）\n",
    "train_and_evaluate_mode = 0\n",
    "# 是否使用最佳的checkpoint进行验证，当为True时，从已保存的checkpoint模型中选择最佳的模型进行预测；\n",
    "# 当为False时，使用最后一个checkpoint模型进行预测；仅在train_and_evaluate_mode=0时有效，CLUE默认采用False\n",
    "apply_best_checkpoint = False\n",
    "# early stop参数，执行若干步时指标任未提升时停止训练模型，仅在train_and_evaluate_mode=1时有效\n",
    "max_steps_without_increase = 500\n",
    "# early stop参数，最低训练若干步时才执行early stop策略，仅在train_and_evaluate_mode=1时有效\n",
    "min_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化训练器\n",
    "trainer = Trainer(\n",
    "    output_dir=output_dir, \n",
    "    random_seed=random_seed)\n",
    "# 构建模型\n",
    "trainer.build_model(\n",
    "    model_name=model_name,\n",
    "    model_type=model_type,\n",
    "    vocab_file=vocab_file,\n",
    "    config_file=config_file,\n",
    "    init_checkpoint_file=init_checkpoint_file,\n",
    "    max_seq_len=max_seq_len)\n",
    "# 加载数据\n",
    "trainer.load_data(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    recreate_tfrecord=recreate_tfrecord)\n",
    "# 执行训练并输出保存好的模型路径（包含checkpoint模型和pb模型）\n",
    "model_file_dict = trainer.train_and_evaluate(\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_proportion=warmup_proportion,\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer_name=optimizer_name,\n",
    "    log_steps=log_steps,\n",
    "    metric_name=metric_name,\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    max_steps_without_increase=max_steps_without_increase,\n",
    "    min_steps=min_steps,\n",
    "    mode=train_and_evaluate_mode,\n",
    "    apply_best_checkpoint=apply_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model save path: \\n%s' % '\\n'.join(['%s: %s' % item for item in model_file_dict.items()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
